{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "805a1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "\n",
    "def get_landmark_model():\n",
    "    # Download the dlib pre-trained facial landmark detector\n",
    "    # This will download a file called 'shape_predictor_68_face_landmarks.dat'\n",
    "    # into the current working directory\n",
    "    dlib_model_url = 'http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2'\n",
    "    dlib_model_file = 'shape_predictor_68_face_landmarks.dat'\n",
    "    dlib_model_path = os.path.join(\"E:\\\\shape_predictor_68_face_landmarks.dat\")\n",
    "    if not os.path.exists(dlib_model_path):\n",
    "        print('Downloading dlib facial landmark detection model...')\n",
    "        urllib.request.urlretrieve(dlib_model_url, dlib_model_path)\n",
    "\n",
    "    # Load the dlib facial landmark detector\n",
    "    landmark_model = dlib.shape_predictor(dlib_model_path)\n",
    "\n",
    "    return landmark_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f530bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Load the landmark model\n",
    "landmark_model = get_landmark_model()\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(\"E:\\\\Rakshith\\\\Photos.jpg\")\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect the faces in the image\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "faces = detector(gray, 1)\n",
    "\n",
    "# Loop over the faces and detect the facial landmarks\n",
    "for face in faces:\n",
    "    landmarks = landmark_model(gray, face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "653517e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "\n",
    "def get_face_detector():\n",
    "    # Download the dlib pre-trained face detector\n",
    "    # This will download a file called 'mmod_human_face_detector.dat'\n",
    "    # into the current working directory\n",
    "    dlib_model_url = 'http://dlib.net/files/mmod_human_face_detector.dat.bz2'\n",
    "    dlib_model_file = 'mmod_human_face_detector.dat'\n",
    "    dlib_model_path = os.path.join(\"E:\\\\mmod_human_face_detector.dat\")\n",
    "    if not os.path.exists(dlib_model_path):\n",
    "        print('Downloading dlib face detection model...')\n",
    "        urllib.request.urlretrieve(dlib_model_url, dlib_model_path)\n",
    "\n",
    "    # Load the dlib face detector\n",
    "    face_detector = dlib.cnn_face_detection_model_v1(dlib_model_path)\n",
    "\n",
    "    return face_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f758f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# Load the face detector model\n",
    "face_detector = get_face_detector()\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(\"E:\\\\Rakshith\\\\Photos.jpg\")\n",
    "\n",
    "# Detect the faces in the image\n",
    "detections = face_detector(image, 1)\n",
    "\n",
    "# Loop over the detections and do something with them\n",
    "for detection in detections:\n",
    "    left = detection.rect.left()\n",
    "    top = detection.rect.top()\n",
    "    right = detection.rect.right()\n",
    "    bottom = detection.rect.bottom()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08e829f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "874f22a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "\n",
    "def find_faces(image, face_detector):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the grayscale image\n",
    "    faces = face_detector(gray, 1)\n",
    "    \n",
    "    # Return the list of faces as rectangles\n",
    "    return [(face.left(), face.top(), face.right(), face.bottom()) for face in faces]\n",
    "\n",
    "    # Return the list of faces\n",
    "    return faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eafa20f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "\n",
    "def find_faces(image, detector):\n",
    "    face_detector = detector\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    rects = face_detector(gray, 0)\n",
    "    return rects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d816df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_marks(img, model, face):\n",
    "    offset_y = int(abs((face.rect.bottom() - face.rect.top()) * 0.1))\n",
    "    box_moved = move_box([face.rect.left(), face.rect.top(), face.rect.right(), face.rect.bottom()], [0, offset_y])\n",
    "    facebox = get_square_box(box_moved)\n",
    "\n",
    "    face_img = img[facebox[1]: facebox[3],\n",
    "               facebox[0]: facebox[2]]\n",
    "    try:\n",
    "        # Converting the face image to grayscale\n",
    "        face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Applying Gaussian blur\n",
    "        face_img = cv2.GaussianBlur(face_img, (5, 5), 0)\n",
    "\n",
    "        # Resizing the face image to 96x96 for landmark detection\n",
    "        face_img = cv2.resize(face_img, (96, 96))\n",
    "\n",
    "        # Normalizing the pixel values\n",
    "        face_img = face_img / 255.0\n",
    "\n",
    "        # Adding a batch dimension to the face image\n",
    "        face_img = np.expand_dims(face_img, axis=0)\n",
    "\n",
    "        # Detecting landmarks in the face image\n",
    "        marks = model.predict(face_img)[0]\n",
    "        \n",
    "        # Converting the landmarks to (x, y) coordinates\n",
    "        marks = np.array([(int(x * facebox[2] + facebox[0]), int(y * facebox[3] + facebox[1])) for (x, y) in marks])\n",
    "\n",
    "        return marks\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0952e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_marks(img, model, face):\n",
    "    # Check if face is valid\n",
    "    if face is None:\n",
    "        return None\n",
    "    \n",
    "    # Calculate offset for mouth\n",
    "    offset_y = int(abs((face.rect.bottom() - face.rect.top()) * 0.1))\n",
    "    \n",
    "    # Move the face box down by the offset\n",
    "    face_box = [face.rect.left(), face.rect.top() + offset_y, face.rect.right(), face.rect.bottom() + offset_y]\n",
    "    \n",
    "    # Get square box around face\n",
    "    face_box = get_square_box(face_box)\n",
    "    \n",
    "    # Extract face image\n",
    "    face_img = img[face_box[1]:face_box[3], face_box[0]:face_box[2]]\n",
    "    \n",
    "    # Detect facial landmarks\n",
    "    marks = []\n",
    "    try:\n",
    "        marks = detect_landmarks(face_img, model)\n",
    "    except:\n",
    "        print(\"Failed to detect landmarks\")\n",
    "        return None\n",
    "    \n",
    "    # Convert coordinates to global coordinates\n",
    "    marks = [(mark[0] + face_box[0], mark[1] + face_box[1]) for mark in marks]\n",
    "    \n",
    "    return marks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f185a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_box(box, offset):\n",
    "    x1, y1, x2, y2 = box\n",
    "    x1 += offset[0]\n",
    "    y1 += offset[1]\n",
    "    x2 += offset[0]\n",
    "    y2 += offset[1]\n",
    "    return [x1, y1, x2, y2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c41d3629",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_square_box(box):\n",
    "        \"\"\"Get a square box out of the given box, by expanding it.\"\"\"\n",
    "        left_x = box[0]\n",
    "        top_y = box[1]\n",
    "        right_x = box[2]\n",
    "        bottom_y = box[3]\n",
    "\n",
    "        box_width = right_x - left_x\n",
    "        box_height = bottom_y - top_y\n",
    "\n",
    "        # Check if box is already a square. If not, make it a square.\n",
    "        diff = box_height - box_width\n",
    "        delta = int(abs(diff) / 2)\n",
    "\n",
    "        if diff == 0:  # Already a square.\n",
    "            return box\n",
    "        elif diff > 0:  # Height > width, a slim box.\n",
    "            left_x -= delta\n",
    "            right_x += delta\n",
    "            if diff % 2 == 1:\n",
    "                right_x += 1\n",
    "        else:  # Width > height, a short box.\n",
    "            top_y -= delta\n",
    "            bottom_y += delta\n",
    "            if diff % 2 == 1:\n",
    "                bottom_y += 1\n",
    "\n",
    "        # Make sure box is always square.\n",
    "        assert ((right_x - left_x) == (bottom_y - top_y)), 'Box is not square.'\n",
    "\n",
    "        return [left_x, top_y, right_x, bottom_y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94a3d19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_marks(image, marks, color=(0, 255, 0)):\n",
    "    \"\"\"\n",
    "    Draws facial landmark points on the image.\n",
    "\n",
    "    Args:\n",
    "    image: A numpy array representing an image.\n",
    "    marks: A numpy array of shape (68, 2) containing the x, y coordinates of facial landmark points.\n",
    "    color: A tuple representing the color of the points.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    if marks is not None:\n",
    "        for mark in marks:\n",
    "            cv2.circle(image, (mark[0], mark[1]), 2, color, -1, cv2.LINE_AA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98064ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to detect landmarks\n",
      "Failed to detect landmarks\n",
      "Failed to detect landmarks\n",
      "Failed to detect landmarks\n",
      "Failed to detect landmarks\n",
      "Failed to detect landmarks\n",
      "Failed to detect landmarks\n",
      "Failed to detect landmarks\n",
      "Failed to detect landmarks\n",
      "Failed to detect landmarks\n",
      "Failed to detect landmarks\n"
     ]
    }
   ],
   "source": [
    "face_model = get_face_detector()\n",
    "landmark_model = get_landmark_model()\n",
    "outer_points = [[49, 59], [50, 58], [51, 57], [52, 56], [53, 55]]\n",
    "d_outer = [0]*5\n",
    "inner_points = [[61, 67], [62, 66], [63, 65]]\n",
    "d_inner = [0]*3\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    rects = find_faces(img, face_model)\n",
    "    for rect in rects:\n",
    "        shape = detect_marks(img, landmark_model, rect)\n",
    "        draw_marks(img, shape)\n",
    "        cv2.putText(img, 'Press r to record Mouth distances', (30, 30), font,\n",
    "                    1, (0, 255, 255), 2)\n",
    "        cv2.imshow(\"Output\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('r'):\n",
    "        for i in range(100):\n",
    "            for i, (p1, p2) in enumerate(outer_points):\n",
    "                d_outer[i] += shape[p2][1] - shape[p1][1]\n",
    "            for i, (p1, p2) in enumerate(inner_points):\n",
    "                d_inner[i] += shape[p2][1] - shape[p1][1]\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "d_outer[:] = [x / 100 for x in d_outer]\n",
    "d_inner[:] = [x / 100 for x in d_inner]\n",
    "\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    rects = find_faces(img, face_model)\n",
    "    for rect in rects:\n",
    "        shape = detect_marks(img, landmark_model, rect)\n",
    "        cnt_outer = 0\n",
    "        cnt_inner = 0\n",
    "        draw_marks(img, shape[48:])\n",
    "        for i, (p1, p2) in enumerate(outer_points):\n",
    "            if d_outer[i] + 3 < shape[p2][1] - shape[p1][1]:\n",
    "                cnt_outer += 1 \n",
    "        for i, (p1, p2) in enumerate(inner_points):\n",
    "            if d_inner[i] + 2 <  shape[p2][1] - shape[p1][1]:\n",
    "                cnt_inner += 1\n",
    "        if cnt_outer > 3 and cnt_inner > 2:\n",
    "            print('Mouth open')\n",
    "            cv2.putText(img, 'Mouth open', (30, 30), font,\n",
    "                    1, (0, 255, 255), 2)\n",
    "        # show the output image with the face detections + facial landmarks\n",
    "    cv2.imshow(\"Output\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7146c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b3cafc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0a24d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
