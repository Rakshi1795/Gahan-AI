{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f5c407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "More than one person detected\n",
      "More than one person detected\n",
      "More than one person detected\n",
      "More than one person detected\n",
      "More than one person detected\n",
      "More than one person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "No person detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "More than one person detected\n",
      "Mobile Phone detected\n",
      "More than one person detected\n",
      "Mobile Phone detected\n",
      "More than one person detected\n",
      "Mobile Phone detected\n",
      "More than one person detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "More than one person detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "More than one person detected\n",
      "Mobile Phone detected\n",
      "More than one person detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "More than one person detected\n",
      "Mobile Phone detected\n",
      "More than one person detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "More than one person detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n",
      "Mobile Phone detected\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Add,\n",
    "    Concatenate,\n",
    "    Conv2D,\n",
    "    Input,\n",
    "    Lambda,\n",
    "    LeakyReLU,\n",
    "    UpSampling2D,\n",
    "    ZeroPadding2D,\n",
    "    BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import wget\n",
    "\n",
    "def load_darknet_weights(model, weights_file):\n",
    "    '''\n",
    "    Helper function used to load darknet weights.\n",
    "    \n",
    "    :param model: Object of the Yolo v3 model\n",
    "    :param weights_file: Path to the file with Yolo V3 weights\n",
    "    '''\n",
    "    \n",
    "    #Open the weights file\n",
    "    wf = open(weights_file, 'rb')\n",
    "    major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
    "\n",
    "    #Define names of the Yolo layers (just for a reference)    \n",
    "    layers = ['yolo_darknet',\n",
    "            'yolo_conv_0',\n",
    "            'yolo_output_0',\n",
    "            'yolo_conv_1',\n",
    "            'yolo_output_1',\n",
    "            'yolo_conv_2',\n",
    "            'yolo_output_2']\n",
    "\n",
    "    for layer_name in layers:\n",
    "        sub_model = model.get_layer(layer_name)\n",
    "        for i, layer in enumerate(sub_model.layers):\n",
    "          \n",
    "            \n",
    "            if not layer.name.startswith('conv2d'):\n",
    "                continue\n",
    "                \n",
    "            #Handles the special, custom Batch normalization layer\n",
    "            batch_norm = None\n",
    "            if i + 1 < len(sub_model.layers) and \\\n",
    "                    sub_model.layers[i + 1].name.startswith('batch_norm'):\n",
    "                batch_norm = sub_model.layers[i + 1]\n",
    "\n",
    "            filters = layer.filters\n",
    "            size = layer.kernel_size[0]\n",
    "            in_dim = layer.input_shape[-1]\n",
    "\n",
    "            if batch_norm is None:\n",
    "                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
    "            else:\n",
    "                # darknet [beta, gamma, mean, variance]\n",
    "                bn_weights = np.fromfile(\n",
    "                    wf, dtype=np.float32, count=4 * filters)\n",
    "                # tf [gamma, beta, mean, variance]\n",
    "                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
    "\n",
    "            # darknet shape (out_dim, in_dim, height, width)\n",
    "            conv_shape = (filters, in_dim, size, size)\n",
    "            conv_weights = np.fromfile(\n",
    "                wf, dtype=np.float32, count=np.product(conv_shape))\n",
    "            # tf shape (height, width, in_dim, out_dim)\n",
    "            conv_weights = conv_weights.reshape(\n",
    "                conv_shape).transpose([2, 3, 1, 0])\n",
    "\n",
    "            if batch_norm is None:\n",
    "                layer.set_weights([conv_weights, conv_bias])\n",
    "            else:\n",
    "                layer.set_weights([conv_weights])\n",
    "                batch_norm.set_weights(bn_weights)\n",
    "\n",
    "    assert len(wf.read()) == 0, 'failed to read all data'\n",
    "    wf.close()\n",
    "    \n",
    "def draw_outputs(img, outputs, class_names):\n",
    "    '''\n",
    "    Helper, util, function that draws predictons on the image.\n",
    "    \n",
    "    :param img: Loaded image\n",
    "    :param outputs: YoloV3 predictions\n",
    "    :param class_names: list of all class names found in the dataset\n",
    "    '''\n",
    "    boxes, objectness, classes, nums = outputs\n",
    "    boxes, objectness, classes, nums = boxes[0], objectness[0], classes[0], nums[0]\n",
    "    wh = np.flip(img.shape[0:2])\n",
    "    for i in range(nums):\n",
    "        x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n",
    "        x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n",
    "        img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)\n",
    "        img = cv2.putText(img, '{} {:.4f}'.format(\n",
    "            class_names[int(classes[i])], objectness[i]),\n",
    "            x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n",
    "    return img\n",
    "\n",
    "yolo_anchors = np.array([(10, 13), (16, 30), (33, 23), (30, 61), (62, 45),\n",
    "                         (59, 119), (116, 90), (156, 198), (373, 326)],\n",
    "                        np.float32) / 416\n",
    "\n",
    "yolo_anchor_masks = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])\n",
    "    \n",
    "def DarknetConv(x, filters, kernel_size, strides=1, batch_norm=True):\n",
    "    '''\n",
    "    Call this function to define a single Darknet convolutional layer\n",
    "    \n",
    "    :param x: inputs\n",
    "    :param filters: number of filters in the convolutional layer\n",
    "    :param kernel_size: Size of kernel in the Conv layer\n",
    "    :param strides: Conv layer strides\n",
    "    :param batch_norm: Whether or not to use the custom batch norm layer.\n",
    "    '''\n",
    "    #Image padding\n",
    "    if strides == 1:\n",
    "        padding = 'same'\n",
    "    else:\n",
    "        x = ZeroPadding2D(((1, 0), (1, 0)))(x)  # top left half-padding\n",
    "        padding = 'valid'\n",
    "        \n",
    "    #Defining the Conv layer\n",
    "    x = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "               strides=strides, padding=padding,\n",
    "               use_bias=not batch_norm, kernel_regularizer=l2(0.0005))(x)\n",
    "    \n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "    return x\n",
    "\n",
    "def DarknetResidual(x, filters):\n",
    "    '''\n",
    "    Call this function to define a single DarkNet Residual layer\n",
    "    \n",
    "    :param x: inputs\n",
    "    :param filters: number of filters in each Conv layer.\n",
    "    '''\n",
    "    prev = x\n",
    "    x = DarknetConv(x, filters // 2, 1)\n",
    "    x = DarknetConv(x, filters, 3)\n",
    "    x = Add()([prev, x])\n",
    "    return x\n",
    "  \n",
    "  \n",
    "def DarknetBlock(x, filters, blocks):\n",
    "    '''\n",
    "    Call this function to define a single DarkNet Block (made of multiple Residual layers)\n",
    "    \n",
    "    :param x: inputs\n",
    "    :param filters: number of filters in each Residual layer\n",
    "    :param blocks: number of Residual layers in the block\n",
    "    '''\n",
    "    x = DarknetConv(x, filters, 3, strides=2)\n",
    "    for _ in range(blocks):\n",
    "        x = DarknetResidual(x, filters)\n",
    "    return x\n",
    "\n",
    "def Darknet(name=None):\n",
    "    '''\n",
    "    The main function that creates the whole DarkNet.\n",
    "    '''\n",
    "    x = inputs = Input([None, None, 3])\n",
    "    x = DarknetConv(x, 32, 3)\n",
    "    x = DarknetBlock(x, 64, 1)\n",
    "    x = DarknetBlock(x, 128, 2)  # skip connection\n",
    "    x = x_36 = DarknetBlock(x, 256, 8)  # skip connection\n",
    "    x = x_61 = DarknetBlock(x, 512, 8)\n",
    "    x = DarknetBlock(x, 1024, 4)\n",
    "    return tf.keras.Model(inputs, (x_36, x_61, x), name=name)\n",
    "\n",
    "def YoloConv(filters, name=None):\n",
    "    '''\n",
    "    Call this function to define the Yolo Conv layer.\n",
    "    \n",
    "    :param flters: number of filters for the conv layer\n",
    "    :param name: name of the layer\n",
    "    '''\n",
    "    def yolo_conv(x_in):\n",
    "        if isinstance(x_in, tuple):\n",
    "            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n",
    "            x, x_skip = inputs\n",
    "\n",
    "            # concat with skip connection\n",
    "            x = DarknetConv(x, filters, 1)\n",
    "            x = UpSampling2D(2)(x)\n",
    "            x = Concatenate()([x, x_skip])\n",
    "        else:\n",
    "            x = inputs = Input(x_in.shape[1:])\n",
    "\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        return Model(inputs, x, name=name)(x_in)\n",
    "    return yolo_conv\n",
    "\n",
    "def YoloOutput(filters, anchors, classes, name=None):\n",
    "    '''\n",
    "    This function defines outputs for the Yolo V3. (Creates output projections)\n",
    "     \n",
    "    :param filters: number of filters for the conv layer\n",
    "    :param anchors: anchors\n",
    "    :param classes: list of classes in a dataset\n",
    "    :param name: name of the layer\n",
    "    '''\n",
    "    def yolo_output(x_in):\n",
    "        x = inputs = Input(x_in.shape[1:])\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, anchors * (classes + 5), 1, batch_norm=False)\n",
    "        x = Lambda(lambda x: tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2],\n",
    "                                            anchors, classes + 5)))(x)\n",
    "        return tf.keras.Model(inputs, x, name=name)(x_in)\n",
    "    return yolo_output\n",
    "\n",
    "def yolo_boxes(pred, anchors, classes):\n",
    "    '''\n",
    "    Call this function to get bounding boxes from network predictions\n",
    "    \n",
    "    :param pred: Yolo predictions\n",
    "    :param anchors: anchors\n",
    "    :param classes: List of classes from the dataset\n",
    "    '''\n",
    "    \n",
    "    # pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...classes))\n",
    "    grid_size = tf.shape(pred)[1]\n",
    "    #Extract box coortinates from prediction vectors\n",
    "    box_xy, box_wh, objectness, class_probs = tf.split(\n",
    "        pred, (2, 2, 1, classes), axis=-1)\n",
    "\n",
    "    #Normalize coortinates\n",
    "    box_xy = tf.sigmoid(box_xy)\n",
    "    objectness = tf.sigmoid(objectness)\n",
    "    class_probs = tf.sigmoid(class_probs)\n",
    "    pred_box = tf.concat((box_xy, box_wh), axis=-1)  # original xywh for loss\n",
    "\n",
    "    # !!! grid[x][y] == (y, x)\n",
    "    grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)  # [gx, gy, 1, 2]\n",
    "\n",
    "    box_xy = (box_xy + tf.cast(grid, tf.float32)) / \\\n",
    "        tf.cast(grid_size, tf.float32)\n",
    "    box_wh = tf.exp(box_wh) * anchors\n",
    "\n",
    "    box_x1y1 = box_xy - box_wh / 2\n",
    "    box_x2y2 = box_xy + box_wh / 2\n",
    "    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\n",
    "\n",
    "    return bbox, objectness, class_probs, pred_box\n",
    "\n",
    "def yolo_nms(outputs, anchors, masks, classes):\n",
    "    # boxes, conf, type\n",
    "    b, c, t = [], [], []\n",
    "\n",
    "    for o in outputs:\n",
    "        b.append(tf.reshape(o[0], (tf.shape(o[0])[0], -1, tf.shape(o[0])[-1])))\n",
    "        c.append(tf.reshape(o[1], (tf.shape(o[1])[0], -1, tf.shape(o[1])[-1])))\n",
    "        t.append(tf.reshape(o[2], (tf.shape(o[2])[0], -1, tf.shape(o[2])[-1])))\n",
    "\n",
    "    bbox = tf.concat(b, axis=1)\n",
    "    confidence = tf.concat(c, axis=1)\n",
    "    class_probs = tf.concat(t, axis=1)\n",
    "\n",
    "    scores = confidence * class_probs\n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "        boxes=tf.reshape(bbox, (tf.shape(bbox)[0], -1, 1, 4)),\n",
    "        scores=tf.reshape(\n",
    "        scores, (tf.shape(scores)[0], -1, tf.shape(scores)[-1])),\n",
    "        max_output_size_per_class=100,\n",
    "        max_total_size=100,\n",
    "        iou_threshold=0.5,\n",
    "        score_threshold=0.6\n",
    "    )\n",
    "\n",
    "    return boxes, scores, classes, valid_detections\n",
    "\n",
    "\n",
    "def YoloV3(size=None, channels=3, anchors=yolo_anchors,\n",
    "           masks=yolo_anchor_masks, classes=80):\n",
    "  \n",
    "    x = inputs = Input([size, size, channels], name='input')\n",
    "\n",
    "    x_36, x_61, x = Darknet(name='yolo_darknet')(x)\n",
    "\n",
    "    x = YoloConv(512, name='yolo_conv_0')(x)\n",
    "    output_0 = YoloOutput(512, len(masks[0]), classes, name='yolo_output_0')(x)\n",
    "\n",
    "    x = YoloConv(256, name='yolo_conv_1')((x, x_61))\n",
    "    output_1 = YoloOutput(256, len(masks[1]), classes, name='yolo_output_1')(x)\n",
    "\n",
    "    x = YoloConv(128, name='yolo_conv_2')((x, x_36))\n",
    "    output_2 = YoloOutput(128, len(masks[2]), classes, name='yolo_output_2')(x)\n",
    "\n",
    "    boxes_0 = Lambda(lambda x: yolo_boxes(x, anchors[masks[0]], classes),\n",
    "                     name='yolo_boxes_0')(output_0)\n",
    "    boxes_1 = Lambda(lambda x: yolo_boxes(x, anchors[masks[1]], classes),\n",
    "                     name='yolo_boxes_1')(output_1)\n",
    "    boxes_2 = Lambda(lambda x: yolo_boxes(x, anchors[masks[2]], classes),\n",
    "                     name='yolo_boxes_2')(output_2)\n",
    "\n",
    "    outputs = Lambda(lambda x: yolo_nms(x, anchors, masks, classes),\n",
    "                     name='yolo_nms')((boxes_0[:3], boxes_1[:3], boxes_2[:3]))\n",
    "\n",
    "    return Model(inputs, outputs, name='yolov3')\n",
    "\n",
    "def weights_download(out='models/yolov3.weights'):\n",
    "    _ = wget.download('https://pjreddie.com/media/files/yolov3.weights', out='models/yolov3.weights')\n",
    "    \n",
    "# weights_download() # to download weights\n",
    "yolo = YoloV3()\n",
    "load_darknet_weights(yolo, \"C:\\\\Users\\\\hp\\\\demo_project_1795\\\\yolov3\\\\models\\\\yolov3.weights\") \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    ret, image = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (320, 320))\n",
    "    img = img.astype(np.float32)\n",
    "    img = np.expand_dims(img, 0)\n",
    "    img = img / 255\n",
    "    class_names = [c.strip() for c in open((\"C:\\\\Users\\\\hp\\\\demo_project_1795\\\\yolov3\\\\models\\\\classes.TXT\")).readlines()]\n",
    "    boxes, scores, classes, nums = yolo(img)\n",
    "    count=0\n",
    "    for i in range(nums[0]):\n",
    "        if int(classes[0][i] == 0):\n",
    "            count +=1\n",
    "        if int(classes[0][i] == 67):\n",
    "            print('Mobile Phone detected')\n",
    "    if count == 0:\n",
    "        print('No person detected')\n",
    "    elif count > 1: \n",
    "        print('More than one person detected')\n",
    "        \n",
    "    image = draw_outputs(image, (boxes, scores, classes, nums), class_names)\n",
    "\n",
    "    cv2.imshow('Prediction', image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4905201a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
